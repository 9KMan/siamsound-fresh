<!DOCTYPE html>
<html>
<head>
  <!--
    If you are serving your web app in a path other than the root, change the
    href value below to reflect the base path you are serving from.

    The path provided below has to start and end with a slash "/" in order for
    it to work correctly.

    For more details:
    * https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base

    This is a placeholder for base href that will be replaced by the value of
    the `--base-href` argument provided to `flutter build`.
  -->
  <base href="/">

  <meta charset="UTF-8">
  <meta content="IE=Edge" http-equiv="X-UA-Compatible">
  <meta name="description" content="An app to explore traditional Thai musical instruments">

  <!-- iOS meta tags & icons -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="apple-mobile-web-app-title" content="Thai Music Explorer">
  <link rel="apple-touch-icon" href="icons/Icon-192.png">

  <!-- Chrome for Android theme color -->
  <meta name="theme-color" content="#0175C2">

  <!-- Windows meta tags -->
  <meta name="msapplication-TileColor" content="#0175C2">
  <meta name="msapplication-TileImage" content="icons/Icon-192.png">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="favicon.png"/>

  <title>Thai Music Explorer</title>
  <link rel="manifest" href="manifest.json">

  <script>
    // iOS Audio Unlock Function with WASM-compatible communication
    (function() {
      let audioUnlocked = false;
      let audioContext = null;
      let iOS = false;
      
      // Detect iOS devices
      function isIOS() {
        return /iPad|iPhone|iPod/.test(navigator.userAgent) || 
               (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
      }
      
      // Create a minimal audio buffer to unlock audio on iOS
      function createUnlockBuffer() {
        if (!audioContext) return;
        const buffer = audioContext.createBuffer(1, 1, 22050);
        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);
        source.start(0);
      }
      
      // Initialize audio context
      function initAudioContext() {
        if (audioContext) return;
        
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        audioContext = new AudioContext();
        
        // Create unlock sound buffer immediately to help maintain context
        createUnlockBuffer();
      }
      
      // Call Flutter method to mark iOS audio as unlocked
      function callFlutterIOSUnlocked() {
        // Use a postMessage approach that's compatible with WASM builds
        if (window.flutterWebRenderer !== undefined) {
          // Check if the Flutter app is loaded and has the method
          if (window.flutter_inappwebview && window.flutter_inappwebview.callHandler) {
            window.flutter_inappwebview.callHandler('onIOSAudioUnlocked', true);
          } else if (window.FlutterApp) {
            window.FlutterApp.onIOSAudioUnlocked && window.FlutterApp.onIOSAudioUnlocked();
          } else if (window.flutter) {
            // Standard Flutter web approach
            const msg = {
              "name": "onIOSAudioUnlocked",
              "args": {}
            };
            window.parent.postMessage(msg, "*");
          } else {
            // Fallback: try direct access to Flutter's engine
            // This approach is compatible with Flutter web standard approach
            if (window.flutterApp || window.flutterLoader) {
              // Try to communicate through Flutter's messaging system if available
              setTimeout(() => {
                // Try to find Flutter's message handler
                if (window.flutter_bootstrap) {
                  // This is a placeholder for communication if needed
                  // We'll use window function approach next
                }
              }, 100);
            }
          }
        }
        
        // More direct approach: call Flutter method if available
        if (window.flutter) {
          // If window.flutter exists, try to call the method directly
          try {
            window.flutter.invokeMethod && window.flutter.invokeMethod('onIOSAudioUnlocked');
          } catch (e) {
            // If direct method fails, add a global function that Flutter can check
            window.onIOSAudioUnlocked = function() {
              // This will be called by Flutter
            };
            
            // Set a flag that Flutter can check
            window.iosAudioUnlocked = true;
          }
        } else {
          // Set a global flag that Flutter can check periodically
          window.iosAudioUnlocked = true;
          
          // Try to access Flutter's engine instance if loaded
          const flutterApp = document.querySelector('#flutter-app') || document.querySelector('#app') || document.querySelector('flt-glass-pane');
          if (flutterApp && flutterApp.shadowRoot) {
            // Custom element might have methods
          }
        }
      }
      
      // Unlock function
      function unlockIOSAudio() {
        if (audioUnlocked) return;
        
        initAudioContext();
        
        // Try to resume the context if it's suspended
        if (audioContext.state === 'suspended') {
          audioContext.resume().then(() => {
            audioUnlocked = true;
            callFlutterIOSUnlocked();
          }).catch((err) => {
            console.warn('Failed to resume audio context:', err);
          });
        } else {
          audioUnlocked = true;
          callFlutterIOSUnlocked();
        }
        
        // Remove event listeners after unlock
        document.removeEventListener('touchstart', unlockIOSAudio);
        document.removeEventListener('click', unlockIOSAudio);
        document.removeEventListener('touchend', unlockIOSAudio);
      }
      
      // Check if iOS and set up unlock
      if (isIOS()) {
        iOS = true;
        document.addEventListener('touchstart', unlockIOSAudio, { once: true });
        document.addEventListener('click', unlockIOSAudio, { once: true });
        document.addEventListener('touchend', unlockIOSAudio, { once: true });
      }
      
      // Also initialize on load as a backup
      window.addEventListener('load', function() {
        // Ensure audio context exists on load
        if (isIOS() && !audioContext) {
          initAudioContext();
        }
      });
    })();
  
    // Additional iOS audio enhancement for more reliable audio playback
    (function() {
      const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) || 
                    (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
      
      if (isIOS) {
        let audioContext;
        let unlocked = false;
        
        // Create a minimal audio buffer to unlock audio on iOS
        function createUnlockBuffer() {
          if (!audioContext) return;
          const buffer = audioContext.createBuffer(1, 1, 22050);
          const source = audioContext.createBufferSource();
          source.buffer = buffer;
          source.connect(audioContext.destination);
          source.start(0);
        }
        
        // Initialize audio context and unlock mechanism
        function initIOSAudio() {
          if (audioContext) return;
          
          try {
            const AudioContext = window.AudioContext || window.webkitAudioContext;
            audioContext = new AudioContext();
            // Create a minimal buffer immediately to try to keep context alive
            createUnlockBuffer();
            
            // Create unlock function
            const unlock = function() {
              if (unlocked) return;
              
              // Create empty buffer and play it
              const buffer = audioContext.createBuffer(1, 1, 22050);
              const source = audioContext.createBufferSource();
              source.buffer = buffer;
              source.connect(audioContext.destination);
              source.start(0);
              
              // Check if it's unlocked after a short delay
              setTimeout(() => {
                if (audioContext && audioContext.state === 'running') {
                  unlocked = true;
                  document.body.removeEventListener('touchstart', unlock);
                  document.body.removeEventListener('click', unlock);
                  
                  // Notify Dart side that audio is unlocked using multiple methods
                  window.iosAudioUnlocked = true;
                  
                  // Try to call Flutter method directly
                  if (window.FlutterApi) {
                    window.FlutterApi.onIOSAudioUnlocked && 
                    window.FlutterApi.onIOSAudioUnlocked();
                  }
                }
              }, 0);
            };
            
            // Setup unlock events on first interaction
            document.body.addEventListener('touchstart', unlock, { once: true });
            document.body.addEventListener('click', unlock, { once: true });
          } catch (e) {
            console.warn('iOS Audio Context initialization failed:', e);
          }
        }
        
        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', initIOSAudio);
        
        // Also try to initialize on first user interaction
        document.addEventListener('touchstart', initIOSAudio, { once: true });
        document.addEventListener('click', initIOSAudio, { once: true });
      }
    })();
  
    // Enhanced iOS Audio Context Management - handles suspended contexts and maintains state
    (function() {
      if (/iPad|iPhone|iPod/.test(navigator.userAgent) || 
          (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1)) {
        
        let audioContext;
        let resumeAttempts = 0;
        const maxResumeAttempts = 3;
        let unlockPromise = null;
        
        // Create a minimal audio buffer to unlock audio on iOS
        function createUnlockBuffer() {
          if (!audioContext) return;
          const buffer = audioContext.createBuffer(1, 1, 22050);
          const source = audioContext.createBufferSource();
          source.buffer = buffer;
          source.connect(audioContext.destination);
          source.start(0);
        }
        
        function getAudioContext() {
          if (!window.AudioContext) window.AudioContext = window.webkitAudioContext;
          if (!audioContext) {
            audioContext = new AudioContext();
            // Create a minimal buffer immediately to try to keep context alive
            createUnlockBuffer();
          }
          return audioContext;
        }
        
        // Function to resume suspended audio context
        function resumeIOSAudioContext() {
          if (!audioContext) {
            // Initialize audio context if not already done
            try {
              getAudioContext();
            } catch (e) {
              console.warn('Could not create audio context:', e);
              return;
            }
          }
          
          if (audioContext.state === 'suspended' || audioContext.state === 'closed') {
            const resumePromise = audioContext.resume().then(() => {
              console.log('Audio context resumed successfully');
              resumeAttempts = 0;
              
              // Ensure context is properly unlocked
              if (audioContext.state === 'running') {
                // Call Flutter notification method
                window.iosAudioUnlocked = true;
                
                // Try to communicate with Flutter that context is active
                if (window.FlutterApi) {
                  window.FlutterApi.onIOSAudioUnlocked && 
                  window.FlutterApi.onIOSAudioUnlocked();
                }
              }
            }).catch((err) => {
              console.warn('Failed to resume audio context:', err);
              if (resumeAttempts < maxResumeAttempts) {
                resumeAttempts++;
                setTimeout(resumeIOSAudioContext, 100);
              }
            });
            
            // Return the promise to allow chaining
            return resumePromise;
          } else if (audioContext.state === 'running') {
            // Context is already running, just return a resolved promise
            return Promise.resolve();
          }
        }
        
        // Function to initialize and unlock audio context on first user interaction
        function initAndUnlockAudio() {
          if (unlockPromise) return unlockPromise; // Prevent multiple concurrent unlocks
          
          unlockPromise = new Promise((resolve, reject) => {
            try {
              getAudioContext();
              
              // Try to resume the context immediately
              resumeIOSAudioContext().then(() => {
                if (audioContext && audioContext.state === 'running') {
                  // Set flag and try to notify Flutter
                  window.iosAudioUnlocked = true;
                  
                  if (window.FlutterApi) {
                    window.FlutterApi.onIOSAudioUnlocked && 
                    window.FlutterApi.onIOSAudioUnlocked();
                  }
                  
                  resolve(audioContext);
                } else {
                  reject(new Error('Audio context not running after resume'));
                }
              }).catch(reject);
            } catch (e) {
              console.error('Error initializing audio context:', e);
              reject(e);
            }
          });
          
          return unlockPromise;
        }
        
        // Monitor for context suspension and visibility changes
        document.addEventListener('visibilitychange', function() {
          if (!document.hidden && audioContext) {
            setTimeout(resumeIOSAudioContext, 100);
          }
        });
        
        // Handle page focus/blur to maintain audio context
        window.addEventListener('focus', function() {
          if (audioContext && (audioContext.state === 'suspended' || audioContext.state === 'closed')) {
            resumeIOSAudioContext();
          }
        });
        
        // Also resume on user interactions
        document.addEventListener('touchstart', function() {
          resumeIOSAudioContext();
        }, { once: false });
        
        document.addEventListener('click', function() {
          resumeIOSAudioContext();
        }, { once: false });
        
        document.addEventListener('touchend', function() {
          // Sometimes touchend is needed instead of touchstart to unlock
          resumeIOSAudioContext();
        }, { once: false });
        
        // Try to initialize audio context on load with a small delay
        window.addEventListener('load', function() {
          setTimeout(() => {
            getAudioContext();
          }, 500);
        });
        
        // Expose function for Flutter to call to initialize and resume context
        window.initAndUnlockAudio = initAndUnlockAudio;
        window.resumeIOSAudioContext = resumeIOSAudioContext;
        
        // Also expose a function that Flutter can call to ensure context is active
        window.ensureAudioContextActive = function() {
          if (audioContext && audioContext.state !== 'running') {
            return resumeIOSAudioContext();
          }
          return Promise.resolve();
        };
      }
    })();
  </script>
</head>
<body>
  <script src="flutter_bootstrap.js" async></script>
</body>
</html>
